{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from detorch import Strategy\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from networks import Network\n",
    "from optimneuralts import OptimNeuralTS\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_cpu = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    using_cpu = False\n",
    "\n",
    "num_cpus = len(os.sched_getaffinity(0))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "torch.set_num_threads(num_cpus)\n",
    "\n",
    "#### SET UP ####\n",
    "args = parse_args()\n",
    "\n",
    "\n",
    "#### PARAMETERS ####\n",
    "n_trials = args.trials\n",
    "dataset = args.dataset\n",
    "thresh = args.threshold\n",
    "seed = args.seed\n",
    "width = args.width\n",
    "n_hidden_layers = args.layers\n",
    "reg = args.reg\n",
    "exploration_mult = args.exploration\n",
    "n_epochs = args.n_epochs\n",
    "lr = args.lr\n",
    "style = args.style\n",
    "optim_string = args.optimizer\n",
    "n_warmup = args.warmup\n",
    "pop_optim_n_members = args.pop_n_members\n",
    "pop_optim_n_steps = args.pop_n_steps\n",
    "pop_optim_lr = args.pop_lr\n",
    "batch_size = args.batch_size\n",
    "n_sigmas = args.n_sigmas\n",
    "ci_thresh = args.ci_thresh\n",
    "patience = args.patience\n",
    "valtype = args.valtype\n",
    "batch_norm = not args.nobatchnorm\n",
    "lds = args.lds\n",
    "use_decay = args.usedecay\n",
    "n_train = args.ntrain\n",
    "train_every = args.train_every\n",
    "\n",
    "if lds == \"True\" or lds == \"False\":\n",
    "    lds = lds == \"True\"\n",
    "\n",
    "make_deterministic(seed)\n",
    "\n",
    "\n",
    "class DEConfig:\n",
    "    n_step: int = pop_optim_n_steps\n",
    "    population_size: int = pop_optim_n_members\n",
    "    differential_weight: float = 1\n",
    "    crossover_probability: float = 0.9\n",
    "    strategy: Strategy = Strategy.best1bin\n",
    "    seed: int = \"doesn't matter\"\n",
    "\n",
    "\n",
    "combis, risks, pat_vecs, n_obs, n_dim = load_dataset(dataset)\n",
    "init_probas = torch.tensor([1 / len(combis)] * len(combis))\n",
    "\n",
    "reward_fn = lambda idx: (\n",
    "    risks[idx] + torch.normal(torch.tensor([0.0]), torch.tensor([0.1])),\n",
    "    risks[idx],\n",
    ")\n",
    "\n",
    "#### SET UP NETWORK AND DE ####\n",
    "de_config = DEConfig\n",
    "de_policy = PullPolicy\n",
    "net = Network(\n",
    "    n_dim, n_hidden_layers, n_output=1, hidden_size=width, batch_norm=batch_norm\n",
    ").to(device)\n",
    "\n",
    "#### METRICS ####\n",
    "recalls = []\n",
    "precisions = []\n",
    "ratio_found_pats = []\n",
    "recalls_alls = []\n",
    "precisions_alls = []\n",
    "ratio_found_pats_alls = []\n",
    "n_inter_alls = []\n",
    "losses = []\n",
    "dataset_losses = []\n",
    "all_flagged_combis_idx = set()\n",
    "all_flaggeds_risks = []\n",
    "all_flagged_pats_idx = set()\n",
    "\n",
    "# Define true solution\n",
    "true_sol_idx = torch.where(risks > thresh)[0]\n",
    "true_sol = combis[true_sol_idx]\n",
    "true_sol_idx = set(true_sol_idx.tolist())\n",
    "n_combis_in_sol = len(true_sol_idx)\n",
    "\n",
    "logging.info(f\"There are {n_combis_in_sol} combinations in the solution set\")\n",
    "\n",
    "agent = OptimNeuralTS(\n",
    "    net,\n",
    "    optim_string,\n",
    "    nu=exploration_mult,\n",
    "    lambda_=reg,\n",
    "    style=style,\n",
    "    valtype=valtype,\n",
    ")\n",
    "\n",
    "vecs, rewards = gen_warmup_vecs_and_rewards(n_warmup, combis, risks, init_probas)\n",
    "\n",
    "X_train, y_train, X_val, y_val = get_data_splits(vecs, rewards, valtype=valtype)\n",
    "\n",
    "agent.train_dataset.set_(X_train, y_train)\n",
    "if valtype != \"noval\":\n",
    "    agent.val_dataset.set_(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Warming up...\")\n",
    "#### WARMUP ####\n",
    "agent.net.eval()\n",
    "i = 0\n",
    "for vec in agent.train_dataset.features:\n",
    "    activ, grad = agent.compute_activation_and_grad(vec[None])\n",
    "    agent.U += grad * grad\n",
    "\n",
    "    if (i + 1) % train_every == 0:\n",
    "        agent.net.train()\n",
    "        loss = agent.train(\n",
    "            n_epochs,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            patience=patience,\n",
    "            lds=lds,\n",
    "            n_train=n_train,\n",
    "            use_decay=use_decay,\n",
    "        )\n",
    "        agent.net.eval()\n",
    "\n",
    "    if (i + 1) % 200 == 0:\n",
    "        (\n",
    "            recall,\n",
    "            precision,\n",
    "            percent_found_pat,\n",
    "            n_inter,\n",
    "            recall_all,\n",
    "            precision_all,\n",
    "            percent_found_pat_all,\n",
    "            n_inter_all,\n",
    "            all_flagged_combis_idx,\n",
    "            all_flagged_pats_idx,\n",
    "        ) = compute_metrics(\n",
    "            agent,\n",
    "            combis,\n",
    "            thresh,\n",
    "            pat_vecs,\n",
    "            true_sol_idx,\n",
    "            n_sigmas,\n",
    "            all_flagged_combis_idx,\n",
    "            all_flagged_pats_idx,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dataset_activ = agent.net(combis)\n",
    "            dataset_loss = agent.loss_func(dataset_activ, risks)\n",
    "            dataset_losses.append(dataset_loss.item())\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        ratio_found_pats.append(percent_found_pat)\n",
    "        recalls_alls.append(recall_all)\n",
    "        precisions_alls.append(precision_all)\n",
    "        ratio_found_pats_alls.append(percent_found_pat_all)\n",
    "        n_inter_alls.append(n_inter_all)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f\"trial: {i + 1}, recall: {recall}, precision: {precision}, ratio of patterns found: {percent_found_pat}, n_inter: {n_inter}, loss: {loss}, dataset_loss: {dataset_loss}\"\n",
    "        )\n",
    "        logging.info(\n",
    "            f\"recall all: {recall_all}, precision all: {precision_all}, ratio of patterns found all: {percent_found_pat_all}, n_inter all: {n_inter_all}\"\n",
    "        )\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "output_dir = args.output\n",
    "l = [\n",
    "    \"agents\",\n",
    "    \"recalls\",\n",
    "    \"precisions\",\n",
    "    \"ratio_found_pats\",\n",
    "    \"losses\",\n",
    "    \"dataset_losses\",\n",
    "    \"recalls_alls\",\n",
    "    \"precisions_alls\",\n",
    "    \"ratio_found_pats_alls\",\n",
    "    \"n_inter_alls\",\n",
    "    \"all_flagged_combis_idx\",\n",
    "    \"all_flagged_risks\",\n",
    "]\n",
    "\n",
    "if len(all_flagged_combis_idx) > 0:\n",
    "    all_flagged_risks = risks[torch.tensor(list(all_flagged_combis_idx))]\n",
    "else:  # Should be IndexError but CC clusters seem to error in C, not in Python\n",
    "    logging.info(\"No flagged combination during the entire experiment\")\n",
    "    logging.info(\"all_flagged_risks is now an empty tensor\")\n",
    "    all_flagged_risks = torch.tensor([])\n",
    "\n",
    "for item in l:\n",
    "    os.makedirs(f\"{output_dir}/{item}/\", exist_ok=True)\n",
    "\n",
    "torch.save(agent, f\"{output_dir}/agents/{seed}.pth\")\n",
    "torch.save(recalls, f\"{output_dir}/recalls/{seed}.pth\")\n",
    "torch.save(precisions, f\"{output_dir}/precisions/{seed}.pth\")\n",
    "torch.save(ratio_found_pats, f\"{output_dir}/ratio_found_pats/{seed}.pth\")\n",
    "torch.save(losses, f\"{output_dir}/losses/{seed}.pth\")\n",
    "torch.save(dataset_losses, f\"{output_dir}/dataset_losses/{seed}.pth\")\n",
    "torch.save(recalls_alls, f\"{output_dir}/recalls_alls/{seed}.pth\")\n",
    "torch.save(precisions_alls, f\"{output_dir}/precisions_alls/{seed}.pth\")\n",
    "torch.save(ratio_found_pats_alls, f\"{output_dir}/ratio_found_pats_alls/{seed}.pth\")\n",
    "torch.save(n_inter_alls, f\"{output_dir}/n_inter_alls/{seed}.pth\")\n",
    "torch.save(all_flagged_risks, f\"{output_dir}/all_flagged_risks/{seed}.pth\")\n",
    "torch.save(all_flagged_combis_idx, f\"{output_dir}/all_flagged_combis_idx/{seed}.pth\")\n",
    "\n",
    "logging.info(\"Warm up over. Computing metrics...\")\n",
    "\n",
    "\n",
    "## GET METRICS POST WARMUP, PRE TRAINING ####\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "befb126eefed1eac3999ea03cd33c04972fea3594bbbdccc0dd405378ee4d8b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
