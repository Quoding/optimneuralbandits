{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import floor, ceil\n",
    "from torch.nn.functional import conv1d\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from fit_sup_utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)  # default = (6.4, 4.8)\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 140  # default = 100\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "# plt.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "title_font_size = \"10\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 1.1\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# param_values = {\n",
    "#     \"dataset\": [\n",
    "#         \"50_rx_100000_combis_4_patterns_3\",\n",
    "#         \"100_rx_100000_combis_10_patterns_35\",\n",
    "#         \"1000_rx_100000_combis_10_patterns_25\",\n",
    "#     ],\n",
    "#     \"width\": [False],\n",
    "#     \"hidden\": [False],\n",
    "#     \"n_obs\": [20000],\n",
    "#     \"decay\": [0],\n",
    "#     \"lr\": [0.001],\n",
    "#     \"custom_layers\": [[512, 256, 128], [128, 64, 32], [64, 32]],\n",
    "#     \"reweight\": [None, True, \"sqrt_inv\"],\n",
    "#     \"batch_size\": [32],\n",
    "#     \"dropout_rate\" : [None],\n",
    "#     \"loss\": [[\"mse\"], [\"rmse\"]]\n",
    "# }\n",
    "\n",
    "param_values = {\n",
    "    \"dataset\": [\n",
    "        # \"50_rx_100000_combis_4_patterns_3\",\n",
    "        # \"100_rx_100000_combis_10_patterns_35\",\n",
    "        \"1000_rx_100000_combis_10_patterns_25\",\n",
    "    ],\n",
    "    \"width\": [256],\n",
    "    \"hidden\": [5],\n",
    "    \"n_obs\": [20000],\n",
    "    \"decay\": [0],\n",
    "    \"lr\": [0.0001, \"plateau\"],\n",
    "    \"custom_layers\": [None],\n",
    "    \"reweight\": [\"sqrt_inv\"],\n",
    "    \"batch_size\": [1024, 2048],\n",
    "    \"dropout_rate\" : [None],\n",
    "    \"loss\": [[\"mse\"], [\"rmse\"]],\n",
    "    \"classif_thresh\": [None]\n",
    "}\n",
    "\n",
    "configs = [dict(zip(param_values, v)) for v in product(*param_values.values())]\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What affects overfitting here ?\n",
    "* Optimizer - Adam fits faster and more than SGD\n",
    "* Learning rate - Lower (0.001) seems better than default (1e-2)\n",
    "* Batch size - Lower batch size seems to lead to more overfitting. Larger ones seem to average out extremes in the input dataset during backprop\n",
    "* Net width - Obviously\n",
    "* Hidden layers - Obviously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What helps fitting \"outliers\" ?\n",
    "Fitting is meant in a broad sense here and just means \"Not predicting the mean\"\n",
    "\n",
    "* Lower LR (?) 0.001 is better than 0.01\n",
    "* Label dist. smoothing, but seems to affect validation perf for the \"common\" cluster (not outlier)\n",
    "* Quantile loss seems to help over estimating values properly when using a quantile at 0.75 (i.e. low risk cluster is overestimated to a lesser extent than high risk cluster, which could be good for the bandit algorithm), HOWEVER, fitting a quantile that isn't 50 feels like it could mess up with NeuralTS (since we're not predicting a mean anymore, we're predicting a quantile, and the output of the NN usually goes into a Normal distribution as the mean param)\n",
    "* Label dist smoothing with a bigger batch size seems to help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does not work\n",
    "\n",
    "* l1 loss\n",
    "* High LR (0.01) seems to lead to high bias in validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does work\n",
    "* 3 layers of 128 width seem to be sufficient to overfit in training\n",
    "* lr of 0.001 seem to help that overfitting, nice, lr of 0.01 seems to fail overfitting in some cases (dataset 100 and 50)\n",
    "* mse is better than rmse\n",
    "* If doing LDS, sqrt_inv is better than just True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To try\n",
    "* ~~Very simple network with LDS (like one that can hardly overfit)~~\n",
    "* Transform regression into a classification with the new knowledge\n",
    "* High batch size with sqrt_inv LDS and lower LR\n",
    "* Adaptive LR (Plateau)\n",
    "* Embed combination vectors. Each RX is a word, each combination of Rx is like a sentence. Embedding should pick up a relationship between the Rxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "* Generalize in validation\n",
    "* If unable to generalize in the conventional sense, at least make sure the \"high risk\" cluster is estimated over the \"low risk\" cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "# seeds = list(range(25))\n",
    "seeds = [0]\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_config(config, exp_dir=\"test_encore\", modifier=\"\"):\n",
    "    n_layers = config[\"hidden\"]\n",
    "    width = config[\"width\"]\n",
    "    n_obs = config[\"n_obs\"]\n",
    "    decay = config[\"decay\"]\n",
    "    dataset = config[\"dataset\"]\n",
    "    lr = config[\"lr\"]\n",
    "    custom_layers = config[\"custom_layers\"]\n",
    "    reweight = config[\"reweight\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    dropout_rate = config[\"dropout_rate\"]\n",
    "    loss_name = config[\"loss\"]\n",
    "    classif_thresh = config[\"classif_thresh\"]\n",
    "\n",
    "    criterion = get_loss(*loss_name)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_r2s = []\n",
    "    val_r2s = []\n",
    "    if exp_dir == None:\n",
    "        exp_dir == \"\"    \n",
    "    l = []\n",
    "    for k, v in config.items():\n",
    "        l += [f\"{k}={v}\"]\n",
    "\n",
    "    exp_dir += \"/\" + \"-\".join(l) + f\"-{modifier=}\"\n",
    "\n",
    "    # Train for 25 seeds\n",
    "    for i, seed in enumerate(seeds):\n",
    "        logdir = f\"runs/{exp_dir}/{seed=}\"\n",
    "        writer = SummaryWriter(log_dir=logdir)\n",
    "        min_val_loss = float(\"inf\")\n",
    "        min_train_loss = float(\"inf\")\n",
    "\n",
    "        seed_train_losses = [np.nan] * n_epochs\n",
    "        seed_val_losses = [np.nan] * n_epochs\n",
    "        seed_train_r2s = [np.nan] * n_epochs\n",
    "        seed_val_r2s = [np.nan] * n_epochs\n",
    "        early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "        make_deterministic(seed=seed)\n",
    "\n",
    "        trainloader, training_data, X_val, y_val, n_dim = setup_data(\n",
    "            dataset, batch_size, n_obs, reweight\n",
    "        )\n",
    "\n",
    "        X_train, y_train = training_data.combis, training_data.labels\n",
    "        if custom_layers is not None:\n",
    "            net = VariableNet(n_dim, custom_layers)\n",
    "        else:\n",
    "            net = Network(n_dim, n_layers, width, dropout_rate).to(device)\n",
    "\n",
    "        if lr == \"plateau\":\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=decay)\n",
    "            sched = ReduceLROnPlateau(optim, 'min')\n",
    "        else:\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
    "        ### RECORD MODEL ###\n",
    "        writer.add_graph(net, X_train[0])\n",
    "        \n",
    "        for e in range(n_epochs):\n",
    "            ### TRAIN ###\n",
    "            for X, y in trainloader:\n",
    "                optim.zero_grad()\n",
    "                train_activ = net(X)\n",
    "                train_loss = criterion(train_activ, y)\n",
    "                if loss_name[0] == \"rmse\":\n",
    "                    train_loss = torch.sqrt(train_loss)\n",
    "                train_loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            ### EVAL ###\n",
    "            with torch.no_grad():\n",
    "                # Compute losses\n",
    "                val_activ = net(X_val)\n",
    "                val_loss = criterion(val_activ, y_val)\n",
    "\n",
    "                train_activ = net(X_train)\n",
    "                train_loss = criterion(train_activ, y_train)\n",
    "\n",
    "                if loss_name[0] == \"rmse\":\n",
    "                    train_loss = torch.sqrt(train_loss)\n",
    "                    val_loss = torch.sqrt(val_loss)\n",
    "\n",
    "                val_loss = val_loss.item()\n",
    "                train_loss = train_loss.item()\n",
    "                \n",
    "                # Get R2 metric\n",
    "                train_r2 = r2_score(y_train.cpu().numpy(), train_activ.cpu().numpy())\n",
    "                val_r2 = r2_score(y_val.cpu().numpy(), val_activ.cpu().numpy())\n",
    "\n",
    "                # Save\n",
    "                seed_train_losses[e] = train_loss\n",
    "                seed_val_losses[e] = val_loss\n",
    "                seed_train_r2s[e] = train_r2\n",
    "                seed_val_r2s[e] = val_r2\n",
    "\n",
    "                writer.add_scalar(\"Loss/train\", train_loss, e)\n",
    "                writer.add_scalar(\"Loss/val\", val_loss, e)\n",
    "                writer.add_scalar(\"R2/train\", train_r2, e)\n",
    "                writer.add_scalar(\"R2/val\", val_r2, e)\n",
    "\n",
    "                # Update LR scheduler\n",
    "                if type(lr) == str:\n",
    "                    sched.step(val_loss)\n",
    "\n",
    "                # Update minimums\n",
    "                if val_loss < min_val_loss:\n",
    "                    val_activ_min_loss = val_activ.detach().clone().cpu().numpy()\n",
    "                    train_activ_min_loss = train_activ.detach().clone().cpu().numpy()\n",
    "                    min_val_loss = val_loss\n",
    "                if train_loss < min_train_loss:\n",
    "                    val_activ_mintrain_loss = val_activ.detach().clone().cpu().numpy()\n",
    "                    train_activ_mintrain_loss = (\n",
    "                        train_activ.detach().clone().cpu().numpy()\n",
    "                    )\n",
    "                    min_train_loss = train_loss\n",
    "\n",
    "            ### VERIFY EARLY STOP ###\n",
    "            # Is weird rn but basically we just want to record the first early stop activations, but since we also want the lowest validation error's activation we can't break out yet\n",
    "            if not early_stopping.early_stop:\n",
    "                early_stopping(val_loss, train_activ, val_activ)\n",
    "                if early_stopping.early_stop:\n",
    "                    ### PLOT EARLY STOP REPRESENTATION ###\n",
    "                    train_activ_graph_early_stop = (\n",
    "                        early_stopping.train_activ.cpu().numpy()\n",
    "                    )\n",
    "                    val_activ_graph_early_stop = early_stopping.val_activ.cpu().numpy()\n",
    "                    fig_pgt_train = plot_pred_vs_gt(\n",
    "                        y_train.cpu().numpy(),\n",
    "                        train_activ_graph_early_stop,\n",
    "                        title=\"Prédiction par rapport à la vérité (es) (entrainement)\",\n",
    "                    )\n",
    "\n",
    "                    fig_pgt_val = plot_pred_vs_gt(\n",
    "                        y_val.cpu().numpy(),\n",
    "                        val_activ_graph_early_stop,\n",
    "                        title=\"Prédiction par rapport à la vérité (es) (validation)\",\n",
    "                    )\n",
    "                    writer.add_figure(\"train_pred_vs_gt_es\", fig_pgt_train)\n",
    "                    writer.add_figure(\"val_pred_vs_gt_es\", fig_pgt_val)\n",
    "                    writer.flush()\n",
    "\n",
    "        ### PLOT PRED VS TRUE FOR THIS SEED  (min loss) ###\n",
    "        fig_pgt_train = plot_pred_vs_gt(\n",
    "            y_train.cpu().numpy(),\n",
    "            train_activ_min_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (minval) (entrainement)\",\n",
    "        )\n",
    "\n",
    "        fig_pgt_val = plot_pred_vs_gt(\n",
    "            y_val.cpu().numpy(),\n",
    "            val_activ_min_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (minval) (validation)\",\n",
    "        )\n",
    "\n",
    "        writer.add_figure(\"train_pred_vs_gt_minval\", fig_pgt_train)\n",
    "        writer.add_figure(\"val_pred_vs_gt_minval\", fig_pgt_val)\n",
    "        ### PLOT PRED VS TRUE FOR THIS SEED  (min loss) ###\n",
    "        fig_pgt_train_mintrain = plot_pred_vs_gt(\n",
    "            y_train.cpu().numpy(),\n",
    "            train_activ_mintrain_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (mintrain) (entrainement)\",\n",
    "        )\n",
    "\n",
    "        fig_pgt_val_mintrain = plot_pred_vs_gt(\n",
    "            y_val.cpu().numpy(),\n",
    "            val_activ_mintrain_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (mintrain) (validation)\",\n",
    "        )\n",
    "\n",
    "        writer.add_figure(\"train_pred_vs_gt_mintrain\", fig_pgt_train_mintrain)\n",
    "        writer.add_figure(\"val_pred_vs_gt_mintrain\", fig_pgt_val_mintrain)\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        train_losses.append(seed_train_losses)\n",
    "        val_losses.append(seed_val_losses)\n",
    "        train_r2s.append(seed_train_r2s)\n",
    "        val_r2s.append(seed_val_r2s)\n",
    "    ### PLOT AGGREGATE DATA FOR ALL SEEDS ###\n",
    "    # logdir = f\"runs/{exp_dir}/aggregate\"\n",
    "    # writer = SummaryWriter(log_dir=logdir)\n",
    "\n",
    "    # ### PLOTS ###\n",
    "    # train_losses = np.array(train_losses)\n",
    "    # val_losses = np.array(val_losses)\n",
    "    # fig_loss = plot_losses(n_epochs, train_losses, val_losses)\n",
    "\n",
    "    # train_r2s = np.array(train_r2s)\n",
    "    # val_r2s = np.array(val_r2s)\n",
    "    # fig_r2 = plot_losses(n_epochs, train_r2s, val_r2s)\n",
    "\n",
    "    # writer.add_figure(\"losses\", fig_loss)\n",
    "    # writer.add_figure(\"r2s\", fig_r2)\n",
    "    \n",
    "    # writer.flush()\n",
    "    # writer.close()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    save_metrics(train_losses, f\"metrics/{exp_dir}/train_losses\")\n",
    "    save_metrics(val_losses, f\"metrics/{exp_dir}/val_losses\")\n",
    "    save_metrics(train_r2s, f\"metrics/{exp_dir}/train_r2s\")\n",
    "    save_metrics(val_r2s, f\"metrics/{exp_dir}/val_r2s\")\n",
    "\n",
    "    # print(f\"saved at runs/{exp_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m configs:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000010?line=1'>2</a>\u001b[0m     run_config(config)\n",
      "\u001b[1;32m/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb Cell 14'\u001b[0m in \u001b[0;36mrun_config\u001b[0;34m(config, exp_dir, modifier)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=39'>40</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(patience\u001b[39m=\u001b[39mpatience)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=41'>42</a>\u001b[0m make_deterministic(seed\u001b[39m=\u001b[39mseed)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=43'>44</a>\u001b[0m trainloader, training_data, X_val, y_val, n_dim \u001b[39m=\u001b[39m setup_data(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=44'>45</a>\u001b[0m     dataset, batch_size, n_obs, reweight\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=45'>46</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=47'>48</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m training_data\u001b[39m.\u001b[39mcombis, training_data\u001b[39m.\u001b[39mlabels\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_supervised.ipynb#ch0000009?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m custom_layers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py:289\u001b[0m, in \u001b[0;36msetup_data\u001b[0;34m(dataset, batch_size, n_obs, reweight, classif_thresh)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=287'>288</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup_data\u001b[39m(dataset, batch_size, n_obs, reweight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, classif_thresh\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=288'>289</a>\u001b[0m     combis, risks, _, _, n_dim \u001b[39m=\u001b[39m load_dataset(dataset)\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=290'>291</a>\u001b[0m     combis, risks \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=291'>292</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(combis\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mfloat(),\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=292'>293</a>\u001b[0m         torch\u001b[39m.\u001b[39mtensor(risks\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat(),\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=293'>294</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=295'>296</a>\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m combis[:n_obs], risks[:n_obs]\n",
      "File \u001b[0;32m~/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py:275\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=273'>274</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dataset\u001b[39m(dataset_path):\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=274'>275</a>\u001b[0m     dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../datasets/combinations/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m dataset_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=276'>277</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../datasets/patterns/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m dataset_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/optimneuralbandits/testing/debug/fit_sup_utils.py?line=277'>278</a>\u001b[0m         patterns \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=570'>571</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=572'>573</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=581'>582</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=582'>583</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=583'>584</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=585'>586</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:488\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=484'>485</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=486'>487</a>\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=487'>488</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1047\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1044'>1045</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1045'>1046</a>\u001b[0m     nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m-> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1046'>1047</a>\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1048'>1049</a>\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1049'>1050</a>\u001b[0m         \u001b[39mif\u001b[39;00m col_dict:\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py?line=1050'>1051</a>\u001b[0m             \u001b[39m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:223\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=220'>221</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=221'>222</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=222'>223</a>\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=223'>224</a>\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=224'>225</a>\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:801\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:880\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1073\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1129\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1420\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1412'>1413</a>\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1413'>1414</a>\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1414'>1415</a>\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1415'>1416</a>\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1416'>1417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, DatetimeTZDtype)\n\u001b[0;32m-> <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1419'>1420</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1420'>1421</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1421'>1422</a>\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1422'>1423</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1462'>1463</a>\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1463'>1464</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/quo/Documents/Maitrise/venv/lib/python3.8/site-packages/pandas/core/dtypes/common.py?line=1464'>1465</a>\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for config in configs:\n",
    "    run_config(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ec05a26f12930ec341a8988c0de5d31e9cfb37c98ea12af5353828508f2c236"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
