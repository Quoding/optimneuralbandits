{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import floor, ceil\n",
    "from torch.nn.functional import conv1d\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from fit_sup_utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)  # default = (6.4, 4.8)\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 140  # default = 100\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "# plt.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "title_font_size = \"10\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 1.1\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# param_values = {\n",
    "#     \"dataset\": [\n",
    "#         \"50_rx_100000_combis_4_patterns_3\",\n",
    "#         \"100_rx_100000_combis_10_patterns_35\",\n",
    "#         \"1000_rx_100000_combis_10_patterns_25\",\n",
    "#     ],\n",
    "#     \"width\": [False],\n",
    "#     \"hidden\": [False],\n",
    "#     \"n_obs\": [20000],\n",
    "#     \"decay\": [0],\n",
    "#     \"lr\": [0.001],\n",
    "#     \"custom_layers\": [[512, 256, 128], [128, 64, 32], [64, 32]],\n",
    "#     \"reweight\": [None, True, \"sqrt_inv\"],\n",
    "#     \"batch_size\": [32],\n",
    "#     \"dropout_rate\" : [None],\n",
    "#     \"loss\": [[\"mse\"], [\"rmse\"]]\n",
    "# }\n",
    "\n",
    "param_values = {\n",
    "    \"dataset\": [\n",
    "        # \"50_rx_100000_combis_4_patterns_3\",\n",
    "        # \"100_rx_100000_combis_10_patterns_35\",\n",
    "        \"1000_rx_100000_combis_10_patterns_25\",\n",
    "    ],\n",
    "    \"width\": [128],\n",
    "    \"hidden\": [3],\n",
    "    \"n_obs\": [20000],\n",
    "    \"decay\": [0],\n",
    "    \"lr\": [0.001],\n",
    "    \"custom_layers\": [None],\n",
    "    \"reweight\": [\"sqrt_inv\"],\n",
    "    \"batch_size\": [32],\n",
    "    \"dropout_rate\" : [None],\n",
    "    \"loss\": [[\"quantile\", [0.5, 0.7]]],\n",
    "    \"classif_thresh\": [None],\n",
    "    \"batch_norm\":[True],\n",
    "    \"patience\": [5, 10],\n",
    "    \"validation\": [None]\n",
    "}\n",
    "\n",
    "configs = [dict(zip(param_values, v)) for v in product(*param_values.values())]\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What affects overfitting here ?\n",
    "* Optimizer - Adam fits faster and more than SGD\n",
    "* Learning rate - Lower (0.001) seems better than default (1e-2)\n",
    "* Batch size - Lower batch size seems to lead to more overfitting. Larger ones seem to average out extremes in the input dataset during backprop\n",
    "* Net width - Obviously\n",
    "* Hidden layers - Obviously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What helps fitting \"outliers\" ?\n",
    "Fitting is meant in a broad sense here and just means \"Not predicting the mean\"\n",
    "\n",
    "* Lower LR (?) 0.001 is better than 0.01\n",
    "* Label dist. smoothing, but seems to affect validation perf for the \"common\" cluster (not outlier)\n",
    "* Quantile loss seems to help over estimating values properly when using a quantile at 0.75 (i.e. low risk cluster is overestimated to a lesser extent than high risk cluster, which could be good for the bandit algorithm), HOWEVER, fitting a quantile that isn't 50 feels like it could mess up with NeuralTS (since we're not predicting a mean anymore, we're predicting a quantile, and the output of the NN usually goes into a Normal distribution as the mean param)\n",
    "* Label dist smoothing with a bigger batch size seems to help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does not work\n",
    "\n",
    "* l1 loss\n",
    "* High LR (0.01) seems to lead to high bias in validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does work\n",
    "* 3 layers of 128 width seem to be sufficient to overfit in training\n",
    "* lr of 0.001 seem to help that overfitting, nice, lr of 0.01 seems to fail overfitting in some cases (dataset 100 and 50)\n",
    "* mse is better than rmse\n",
    "* If doing LDS, sqrt_inv is better than just True\n",
    "* for 1000 rx, small batches, sqrt_inv LDS, smaller models seems to have less bias in validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To try\n",
    "* ~~Very simple network with LDS (like one that can hardly overfit)~~\n",
    "* Transform regression into a classification with the new knowledge (how to interpret CIs then ?)\n",
    "* ~~High batch size with sqrt_inv LDS and lower LR~~\n",
    "* ~~Adaptive LR (Plateau)~~\n",
    "* ~~Embed combination vectors. Each RX is a word, each combination of Rx is like a sentence. Embedding should pick up a relationship between the Rxs~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "* Generalize in validation\n",
    "* If unable to generalize in the conventional sense, at least make sure the \"high risk\" cluster is estimated over the \"low risk\" cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "# seeds = list(range(25))\n",
    "seeds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_config(config, exp_dir=\"test_graal\"):\n",
    "    n_layers = config[\"hidden\"]\n",
    "    width = config[\"width\"]\n",
    "    n_obs = config[\"n_obs\"]\n",
    "    decay = config[\"decay\"]\n",
    "    dataset = config[\"dataset\"]\n",
    "    lr = config[\"lr\"]\n",
    "    custom_layers = config[\"custom_layers\"]\n",
    "    reweight = config[\"reweight\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    dropout_rate = config[\"dropout_rate\"]\n",
    "    loss_info = config[\"loss\"]\n",
    "    classif_thresh = config[\"classif_thresh\"]\n",
    "    batch_norm = config[\"batch_norm\"]\n",
    "    patience = config[\"patience\"]\n",
    "    validation = config[\"validation\"]\n",
    "\n",
    "    n_outputs = 1\n",
    "    pred_idx = 0\n",
    "\n",
    "    criterion = get_loss(*loss_info)\n",
    "    if loss_info[0] == \"quantile\":\n",
    "        quantiles = np.array(loss_info[1])\n",
    "        assert 0.5 in quantiles\n",
    "        pred_idx = np.where(quantiles == 0.5)[0][0]\n",
    "        n_outputs = len(quantiles)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_r2s = []\n",
    "    val_r2s = []\n",
    "    if exp_dir == None:\n",
    "        exp_dir == \"\"    \n",
    "    l = []\n",
    "    for k, v in config.items():\n",
    "        l += [f\"{k}={v}\"]\n",
    "\n",
    "    exp_dir += \"/\" + \"/\".join(l)\n",
    "\n",
    "    # Train for 25 seeds\n",
    "    for i, seed in enumerate(seeds):\n",
    "        logdir = f\"runs/{exp_dir}/{seed=}\"\n",
    "        writer = SummaryWriter(log_dir=logdir)\n",
    "        min_val_loss = float(\"inf\")\n",
    "        min_train_loss = float(\"inf\")\n",
    "\n",
    "        seed_train_losses = [np.nan] * n_epochs\n",
    "        seed_val_losses = [np.nan] * n_epochs\n",
    "        seed_train_r2s = [np.nan] * n_epochs\n",
    "        seed_val_r2s = [np.nan] * n_epochs\n",
    "        early_stopping = EarlyStoppingActiv(patience=patience)\n",
    "\n",
    "        make_deterministic(seed=seed)\n",
    "\n",
    "        trainloader, training_data, X_val, y_val, n_dim = setup_data(\n",
    "            dataset, batch_size, n_obs, reweight, classif_thresh, validation\n",
    "        )\n",
    "\n",
    "        X_train, y_train = training_data.combis, training_data.labels\n",
    "        if custom_layers is not None:\n",
    "            net = VariableNet(n_dim, custom_layers)\n",
    "        else:\n",
    "            net = Network(n_dim, n_layers, n_outputs, width, dropout_rate, batch_norm).to(device)\n",
    "\n",
    "        if lr == \"plateau\":\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=decay)\n",
    "            sched = ReduceLROnPlateau(optim, 'min', patience=patience - 2)\n",
    "        else:\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
    "        ### RECORD MODEL ###\n",
    "        writer.add_graph(net, X_train)\n",
    "        \n",
    "        for e in range(n_epochs):\n",
    "            ### TRAIN ###\n",
    "            for X, y in trainloader:\n",
    "                optim.zero_grad()\n",
    "                train_activ = net(X)\n",
    "                train_loss = criterion(train_activ, y)\n",
    "                if loss_info[0] == \"rmse\":\n",
    "                    train_loss = torch.sqrt(train_loss)\n",
    "                train_loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            ### EVAL ###\n",
    "            with torch.no_grad():\n",
    "                # Compute losses\n",
    "                val_activ = net(X_val)\n",
    "                val_loss = criterion(val_activ, y_val)\n",
    "\n",
    "                train_activ = net(X_train)\n",
    "                train_loss = criterion(train_activ, y_train)\n",
    "\n",
    "                if loss_info[0] == \"rmse\":\n",
    "                    train_loss = torch.sqrt(train_loss)\n",
    "                    val_loss = torch.sqrt(val_loss)\n",
    "\n",
    "                val_loss = val_loss.item()\n",
    "                train_loss = train_loss.item()\n",
    "                \n",
    "                # Get R2 metric\n",
    "                train_r2 = r2_score(y_train.cpu().numpy(), train_activ.cpu().numpy()[:, pred_idx])\n",
    "                val_r2 = r2_score(y_val.cpu().numpy(), val_activ.cpu().numpy()[:, pred_idx])\n",
    "\n",
    "                # Save\n",
    "                seed_train_losses[e] = train_loss\n",
    "                seed_val_losses[e] = val_loss\n",
    "                seed_train_r2s[e] = train_r2\n",
    "                seed_val_r2s[e] = val_r2\n",
    "\n",
    "                writer.add_scalar(\"Loss/train\", train_loss, e)\n",
    "                writer.add_scalar(\"Loss/val\", val_loss, e)\n",
    "                writer.add_scalar(\"R2/train\", train_r2, e)\n",
    "                writer.add_scalar(\"R2/val\", val_r2, e)\n",
    "\n",
    "                # Update LR scheduler\n",
    "                if type(lr) == str:\n",
    "                    sched.step(val_loss)\n",
    "\n",
    "                # Update minimums\n",
    "                if val_loss < min_val_loss:\n",
    "                    val_activ_min_loss = val_activ.detach().clone().cpu().numpy()[:, pred_idx]\n",
    "                    train_activ_min_loss = train_activ.detach().clone().cpu().numpy()[:, pred_idx]\n",
    "                    min_val_loss = val_loss\n",
    "                if train_loss < min_train_loss:\n",
    "                    val_activ_mintrain_loss = val_activ.detach().clone().cpu().numpy()[:, pred_idx]\n",
    "                    train_activ_mintrain_loss = (\n",
    "                        train_activ.detach().clone().cpu().numpy()\n",
    "                    )[:, pred_idx]\n",
    "                    min_train_loss = train_loss\n",
    "\n",
    "            ### VERIFY EARLY STOP ###\n",
    "            # Is weird rn but basically we just want to record the first early stop activations, but since we also want the lowest validation error's activation we can't break out yet\n",
    "            if not early_stopping.early_stop:\n",
    "                early_stopping(val_loss, train_activ, val_activ)\n",
    "                if early_stopping.early_stop:\n",
    "                    ### PLOT EARLY STOP REPRESENTATION ###\n",
    "                    train_activ_graph_early_stop = (\n",
    "                        early_stopping.train_activ.cpu().numpy()\n",
    "                    )[:, pred_idx]\n",
    "                    val_activ_graph_early_stop = early_stopping.val_activ.cpu().numpy()[:, pred_idx]\n",
    "                    \n",
    "                    fig_pgt_es = plot_pred_vs_gt(\n",
    "                        y_train.cpu().numpy(),\n",
    "                        train_activ_graph_early_stop,\n",
    "                        y_val.cpu().numpy(),\n",
    "                        val_activ_graph_early_stop,\n",
    "                        title=\"Prédiction par rapport à la vérité (Early Stop)\",\n",
    "                    )\n",
    "\n",
    "                    writer.add_figure(\"pred_vs_gt_early_stop\", fig_pgt_es)\n",
    "                    writer.flush()\n",
    "\n",
    "        ### PLOT PRED VS TRUE FOR THIS SEED  (min val loss) ###\n",
    "        fig_pgt_minval = plot_pred_vs_gt(\n",
    "            y_train.cpu().numpy(),\n",
    "            train_activ_min_loss,\n",
    "            y_val.cpu().numpy(),\n",
    "            val_activ_min_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (min val)\",\n",
    "        )\n",
    "\n",
    "        writer.add_figure(\"pred_vs_gt_minval\", fig_pgt_minval)\n",
    "\n",
    "        ### PLOT PRED VS TRUE FOR THIS SEED  (min train loss) ###\n",
    "        fig_pgt_mintrain = plot_pred_vs_gt(\n",
    "            y_train.cpu().numpy(),\n",
    "            train_activ_mintrain_loss,\n",
    "            y_val.cpu().numpy(),\n",
    "            val_activ_mintrain_loss,\n",
    "            title=\"Prédiction par rapport à la vérité (min train)\",\n",
    "        )\n",
    "\n",
    "        writer.add_figure(\"pred_vs_gt_mintrain\", fig_pgt_mintrain)\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        train_losses.append(seed_train_losses)\n",
    "        val_losses.append(seed_val_losses)\n",
    "        train_r2s.append(seed_train_r2s)\n",
    "        val_r2s.append(seed_val_r2s)\n",
    "    ### PLOT AGGREGATE DATA FOR ALL SEEDS ###\n",
    "    # logdir = f\"runs/{exp_dir}/aggregate\"\n",
    "    # writer = SummaryWriter(log_dir=logdir)\n",
    "\n",
    "    # ### PLOTS ###\n",
    "    # train_losses = np.array(train_losses)\n",
    "    # val_losses = np.array(val_losses)\n",
    "    # fig_loss = plot_losses(n_epochs, train_losses, val_losses)\n",
    "\n",
    "    # train_r2s = np.array(train_r2s)\n",
    "    # val_r2s = np.array(val_r2s)\n",
    "    # fig_r2 = plot_losses(n_epochs, train_r2s, val_r2s)\n",
    "\n",
    "    # writer.add_figure(\"losses\", fig_loss)\n",
    "    # writer.add_figure(\"r2s\", fig_r2)\n",
    "    \n",
    "    # writer.flush()\n",
    "    # writer.close()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    save_metrics(train_losses, f\"metrics/{exp_dir}/train_losses\")\n",
    "    save_metrics(val_losses, f\"metrics/{exp_dir}/val_losses\")\n",
    "    save_metrics(train_r2s, f\"metrics/{exp_dir}/train_r2s\")\n",
    "    save_metrics(val_r2s, f\"metrics/{exp_dir}/val_r2s\")\n",
    "\n",
    "    # print(f\"saved at runs/{exp_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label distribution smoothing\n",
      "tensor([[0.9142, 0.9689],\n",
      "        [1.0110, 1.0695],\n",
      "        [1.0296, 1.0768],\n",
      "        ...,\n",
      "        [1.1986, 1.3782],\n",
      "        [0.9904, 1.0081],\n",
      "        [0.9978, 1.1028]])\n",
      "tensor([[1.1073, 1.1899],\n",
      "        [1.0918, 1.1897],\n",
      "        [1.1496, 1.2760],\n",
      "        ...,\n",
      "        [1.0509, 1.1669],\n",
      "        [1.0258, 1.1295],\n",
      "        [1.1618, 1.2412]])\n",
      "tensor([[1.0039, 1.0639],\n",
      "        [1.0080, 1.0679],\n",
      "        [1.0896, 1.1523],\n",
      "        ...,\n",
      "        [1.0485, 1.1217],\n",
      "        [0.9747, 1.0472],\n",
      "        [1.0845, 1.1505]])\n",
      "tensor([[1.0209, 1.0473],\n",
      "        [1.0104, 1.0577],\n",
      "        [1.1692, 1.2362],\n",
      "        ...,\n",
      "        [1.0663, 1.1245],\n",
      "        [1.0681, 1.1068],\n",
      "        [1.0467, 1.0960]])\n",
      "tensor([[0.9739, 1.0234],\n",
      "        [0.9648, 1.0089],\n",
      "        [1.0890, 1.1192],\n",
      "        ...,\n",
      "        [1.0248, 1.0678],\n",
      "        [0.9545, 0.9941],\n",
      "        [1.0476, 1.0755]])\n",
      "tensor([[0.9833, 1.0128],\n",
      "        [1.0299, 1.0682],\n",
      "        [1.0174, 1.0473],\n",
      "        ...,\n",
      "        [1.0139, 1.0576],\n",
      "        [1.0067, 1.0595],\n",
      "        [1.0163, 1.0503]])\n",
      "tensor([[0.9363, 0.9824],\n",
      "        [0.9928, 1.0221],\n",
      "        [0.9558, 0.9649],\n",
      "        ...,\n",
      "        [0.9389, 0.9633],\n",
      "        [1.0140, 1.0567],\n",
      "        [0.9793, 1.0035]])\n",
      "tensor([[1.0094, 1.0272],\n",
      "        [0.9531, 0.9720],\n",
      "        [0.9622, 0.9595],\n",
      "        ...,\n",
      "        [1.0244, 1.0412],\n",
      "        [1.0773, 1.1012],\n",
      "        [1.0372, 1.0527]])\n",
      "tensor([[1.0127, 1.0595],\n",
      "        [1.0435, 1.1054],\n",
      "        [0.9906, 1.0524],\n",
      "        ...,\n",
      "        [0.9738, 1.0283],\n",
      "        [0.9700, 1.0324],\n",
      "        [1.0823, 1.1620]])\n",
      "tensor([[0.9979, 1.0279],\n",
      "        [0.9656, 0.9935],\n",
      "        [0.9731, 0.9893],\n",
      "        ...,\n",
      "        [1.0019, 1.0291],\n",
      "        [1.0071, 1.0274],\n",
      "        [1.0334, 1.0677]])\n",
      "tensor([[1.0010, 1.0309],\n",
      "        [0.9789, 1.0104],\n",
      "        [0.9552, 0.9810],\n",
      "        ...,\n",
      "        [1.0426, 1.0851],\n",
      "        [0.9185, 0.9430],\n",
      "        [0.9656, 0.9872]])\n",
      "tensor([[1.0443, 1.0402],\n",
      "        [1.0678, 1.0769],\n",
      "        [0.9947, 0.9981],\n",
      "        ...,\n",
      "        [1.0394, 1.0599],\n",
      "        [1.0280, 1.0419],\n",
      "        [1.0475, 1.0443]])\n",
      "tensor([[0.9564, 0.9827],\n",
      "        [1.0006, 1.0216],\n",
      "        [0.9817, 1.0052],\n",
      "        ...,\n",
      "        [1.0266, 1.0614],\n",
      "        [1.0270, 1.0498],\n",
      "        [0.9690, 0.9900]])\n",
      "tensor([[1.0021, 1.0539],\n",
      "        [1.0418, 1.0834],\n",
      "        [0.9813, 1.0156],\n",
      "        ...,\n",
      "        [1.0843, 1.1376],\n",
      "        [0.9647, 0.9930],\n",
      "        [0.9483, 0.9759]])\n",
      "tensor([[0.9916, 1.0252],\n",
      "        [1.0315, 1.0572],\n",
      "        [0.9865, 1.0154],\n",
      "        ...,\n",
      "        [0.9807, 0.9927],\n",
      "        [0.9719, 0.9866],\n",
      "        [0.9990, 1.0191]])\n",
      "tensor([[0.9465, 0.9696],\n",
      "        [0.9871, 1.0257],\n",
      "        [0.9397, 0.9719],\n",
      "        ...,\n",
      "        [1.0242, 1.0643],\n",
      "        [1.0105, 1.0513],\n",
      "        [0.9615, 0.9806]])\n",
      "tensor([[0.9651, 0.9999],\n",
      "        [0.9995, 1.0324],\n",
      "        [0.9506, 0.9750],\n",
      "        ...,\n",
      "        [1.0276, 1.0544],\n",
      "        [0.9622, 0.9885],\n",
      "        [0.9880, 1.0131]])\n",
      "tensor([[0.9220, 0.9473],\n",
      "        [0.9646, 0.9910],\n",
      "        [0.9512, 0.9684],\n",
      "        ...,\n",
      "        [0.9720, 0.9970],\n",
      "        [1.0101, 1.0314],\n",
      "        [0.9993, 1.0233]])\n",
      "tensor([[1.0373, 1.0528],\n",
      "        [1.0223, 1.0411],\n",
      "        [0.9423, 0.9606],\n",
      "        ...,\n",
      "        [1.0143, 1.0316],\n",
      "        [0.9716, 0.9932],\n",
      "        [1.0303, 1.0441]])\n",
      "tensor([[0.9515, 0.9654],\n",
      "        [0.9994, 1.0128],\n",
      "        [0.9407, 0.9785],\n",
      "        ...,\n",
      "        [1.0209, 1.0499],\n",
      "        [1.0166, 1.0401],\n",
      "        [1.0212, 1.0271]])\n",
      "tensor([[0.9452, 0.9659],\n",
      "        [0.9920, 1.0066],\n",
      "        [0.9499, 0.9750],\n",
      "        ...,\n",
      "        [1.0370, 1.0608],\n",
      "        [0.9658, 0.9859],\n",
      "        [1.0026, 1.0238]])\n",
      "tensor([[0.9148, 0.9443],\n",
      "        [0.9882, 1.0067],\n",
      "        [0.9561, 0.9819],\n",
      "        ...,\n",
      "        [1.0145, 1.0469],\n",
      "        [0.9580, 0.9714],\n",
      "        [0.9890, 1.0146]])\n",
      "tensor([[0.9227, 0.9419],\n",
      "        [1.0146, 1.0420],\n",
      "        [0.9674, 0.9801],\n",
      "        ...,\n",
      "        [1.0134, 1.0469],\n",
      "        [0.9779, 1.0023],\n",
      "        [1.0026, 1.0232]])\n",
      "tensor([[0.9400, 0.9503],\n",
      "        [0.9733, 0.9928],\n",
      "        [0.9627, 0.9783],\n",
      "        ...,\n",
      "        [0.9753, 0.9903],\n",
      "        [0.9573, 0.9691],\n",
      "        [1.0292, 1.0470]])\n",
      "tensor([[0.9700, 1.0070],\n",
      "        [1.0121, 1.0477],\n",
      "        [0.9632, 0.9986],\n",
      "        ...,\n",
      "        [0.9761, 1.0086],\n",
      "        [0.9637, 1.0067],\n",
      "        [1.0201, 1.0540]])\n",
      "tensor([[0.9181, 0.9303],\n",
      "        [1.0003, 1.0231],\n",
      "        [0.9546, 0.9780],\n",
      "        ...,\n",
      "        [0.9488, 0.9688],\n",
      "        [0.9739, 0.9946],\n",
      "        [1.0008, 1.0246]])\n",
      "tensor([[0.9406, 0.9544],\n",
      "        [1.0317, 1.0479],\n",
      "        [0.9539, 0.9748],\n",
      "        ...,\n",
      "        [0.9571, 0.9705],\n",
      "        [0.9701, 0.9875],\n",
      "        [1.0543, 1.0821]])\n",
      "tensor([[0.9850, 1.0024],\n",
      "        [1.0273, 1.0406],\n",
      "        [0.9653, 0.9873],\n",
      "        ...,\n",
      "        [0.9503, 0.9726],\n",
      "        [1.0085, 1.0253],\n",
      "        [1.0764, 1.0927]])\n",
      "tensor([[0.9603, 0.9674],\n",
      "        [1.0072, 1.0282],\n",
      "        [0.9427, 0.9609],\n",
      "        ...,\n",
      "        [0.9644, 0.9869],\n",
      "        [0.9910, 1.0131],\n",
      "        [1.0515, 1.0732]])\n",
      "tensor([[0.9679, 0.9751],\n",
      "        [0.9867, 0.9944],\n",
      "        [0.9505, 0.9606],\n",
      "        ...,\n",
      "        [0.9443, 0.9626],\n",
      "        [1.0085, 1.0256],\n",
      "        [1.0312, 1.0384]])\n",
      "tensor([[0.9677, 0.9833],\n",
      "        [1.0053, 1.0109],\n",
      "        [0.9319, 0.9451],\n",
      "        ...,\n",
      "        [0.9580, 0.9835],\n",
      "        [1.0164, 1.0188],\n",
      "        [1.0059, 1.0255]])\n",
      "tensor([[0.9578, 0.9682],\n",
      "        [1.0201, 1.0335],\n",
      "        [0.9395, 0.9485],\n",
      "        ...,\n",
      "        [0.9353, 0.9593],\n",
      "        [1.0392, 1.0376],\n",
      "        [1.0370, 1.0465]])\n",
      "tensor([[0.9829, 1.0003],\n",
      "        [1.0014, 1.0230],\n",
      "        [0.9194, 0.9425],\n",
      "        ...,\n",
      "        [0.9445, 0.9736],\n",
      "        [0.9496, 0.9709],\n",
      "        [1.0275, 1.0533]])\n",
      "tensor([[0.9740, 0.9901],\n",
      "        [1.0121, 1.0319],\n",
      "        [0.9496, 0.9738],\n",
      "        ...,\n",
      "        [0.9635, 0.9783],\n",
      "        [0.9522, 0.9746],\n",
      "        [1.0406, 1.0657]])\n",
      "tensor([[0.9816, 0.9920],\n",
      "        [1.0061, 1.0152],\n",
      "        [0.9454, 0.9550],\n",
      "        ...,\n",
      "        [1.0327, 1.0428],\n",
      "        [0.9713, 0.9673],\n",
      "        [1.0284, 1.0331]])\n",
      "tensor([[0.9609, 0.9759],\n",
      "        [0.9940, 1.0205],\n",
      "        [0.9130, 0.9339],\n",
      "        ...,\n",
      "        [0.9456, 0.9685],\n",
      "        [0.9936, 1.0104],\n",
      "        [1.0074, 1.0235]])\n",
      "tensor([[1.0234, 1.0369],\n",
      "        [1.0002, 1.0229],\n",
      "        [0.9466, 0.9598],\n",
      "        ...,\n",
      "        [0.9696, 0.9918],\n",
      "        [0.9918, 1.0035],\n",
      "        [1.0436, 1.0640]])\n",
      "tensor([[1.0044, 1.0133],\n",
      "        [1.0065, 1.0295],\n",
      "        [0.9413, 0.9560],\n",
      "        ...,\n",
      "        [0.9991, 1.0167],\n",
      "        [0.9799, 1.0042],\n",
      "        [1.0657, 1.0844]])\n",
      "tensor([[0.9842, 0.9915],\n",
      "        [0.9976, 1.0138],\n",
      "        [0.9259, 0.9438],\n",
      "        ...,\n",
      "        [0.9550, 0.9712],\n",
      "        [1.0043, 1.0128],\n",
      "        [1.0235, 1.0374]])\n",
      "tensor([[0.9912, 0.9994],\n",
      "        [1.0270, 1.0363],\n",
      "        [0.9304, 0.9334],\n",
      "        ...,\n",
      "        [1.0087, 1.0180],\n",
      "        [0.9782, 0.9864],\n",
      "        [1.0792, 1.0809]])\n",
      "tensor([[0.9671, 0.9790],\n",
      "        [0.9649, 0.9877],\n",
      "        [0.9049, 0.9248],\n",
      "        ...,\n",
      "        [0.9755, 0.9962],\n",
      "        [0.9627, 0.9764],\n",
      "        [0.9880, 1.0052]])\n",
      "tensor([[0.9758, 0.9843],\n",
      "        [1.0106, 1.0062],\n",
      "        [0.9334, 0.9392],\n",
      "        ...,\n",
      "        [0.9882, 1.0014],\n",
      "        [0.9954, 1.0032],\n",
      "        [1.0222, 1.0300]])\n",
      "tensor([[0.9586, 0.9721],\n",
      "        [0.9964, 1.0148],\n",
      "        [0.9090, 0.9209],\n",
      "        ...,\n",
      "        [0.9699, 0.9849],\n",
      "        [1.0109, 1.0301],\n",
      "        [1.0047, 1.0140]])\n",
      "tensor([[0.9789, 0.9882],\n",
      "        [1.0148, 1.0162],\n",
      "        [0.9127, 0.9224],\n",
      "        ...,\n",
      "        [0.9738, 0.9781],\n",
      "        [0.9960, 1.0072],\n",
      "        [1.0192, 1.0203]])\n",
      "tensor([[0.9997, 1.0056],\n",
      "        [0.9959, 1.0131],\n",
      "        [0.8958, 0.9154],\n",
      "        ...,\n",
      "        [1.0000, 1.0161],\n",
      "        [0.9799, 0.9983],\n",
      "        [1.0099, 1.0211]])\n",
      "tensor([[0.9686, 0.9814],\n",
      "        [0.9839, 1.0015],\n",
      "        [0.8939, 0.9061],\n",
      "        ...,\n",
      "        [0.9843, 0.9982],\n",
      "        [0.9957, 1.0027],\n",
      "        [0.9987, 1.0050]])\n",
      "tensor([[0.9736, 0.9913],\n",
      "        [1.0173, 1.0276],\n",
      "        [0.9331, 0.9482],\n",
      "        ...,\n",
      "        [1.0155, 1.0215],\n",
      "        [1.0025, 1.0088],\n",
      "        [1.0365, 1.0527]])\n",
      "tensor([[0.9794, 0.9949],\n",
      "        [1.0387, 1.0454],\n",
      "        [0.9270, 0.9359],\n",
      "        ...,\n",
      "        [0.9654, 0.9713],\n",
      "        [1.0087, 1.0251],\n",
      "        [1.0589, 1.0597]])\n",
      "tensor([[0.9846, 0.9929],\n",
      "        [1.0174, 1.0227],\n",
      "        [0.9240, 0.9282],\n",
      "        ...,\n",
      "        [0.9799, 0.9915],\n",
      "        [1.0147, 1.0159],\n",
      "        [1.0820, 1.0848]])\n",
      "tensor([[0.9906, 1.0021],\n",
      "        [1.0283, 1.0494],\n",
      "        [0.9182, 0.9325],\n",
      "        ...,\n",
      "        [0.9662, 0.9702],\n",
      "        [0.9883, 0.9993],\n",
      "        [1.0575, 1.0807]])\n",
      "tensor([[0.9965, 1.0178],\n",
      "        [1.0216, 1.0432],\n",
      "        [0.9180, 0.9388],\n",
      "        ...,\n",
      "        [0.9577, 0.9743],\n",
      "        [0.9781, 0.9892],\n",
      "        [1.0437, 1.0667]])\n",
      "tensor([[0.9847, 1.0031],\n",
      "        [1.0362, 1.0424],\n",
      "        [0.9278, 0.9373],\n",
      "        ...,\n",
      "        [0.9452, 0.9596],\n",
      "        [0.9917, 1.0002],\n",
      "        [1.0396, 1.0514]])\n",
      "tensor([[0.9541, 0.9789],\n",
      "        [1.0153, 1.0248],\n",
      "        [0.9522, 0.9651],\n",
      "        ...,\n",
      "        [0.9768, 0.9951],\n",
      "        [0.9816, 0.9937],\n",
      "        [1.0178, 1.0448]])\n",
      "tensor([[0.9991, 1.0057],\n",
      "        [1.0298, 1.0382],\n",
      "        [0.9151, 0.9256],\n",
      "        ...,\n",
      "        [0.9733, 0.9916],\n",
      "        [0.9710, 0.9891],\n",
      "        [1.0201, 1.0354]])\n",
      "tensor([[0.9911, 1.0078],\n",
      "        [1.0176, 1.0232],\n",
      "        [0.9152, 0.9287],\n",
      "        ...,\n",
      "        [0.9829, 0.9954],\n",
      "        [0.9747, 0.9854],\n",
      "        [1.0520, 1.0655]])\n",
      "tensor([[0.9726, 0.9868],\n",
      "        [1.0015, 1.0190],\n",
      "        [0.9198, 0.9330],\n",
      "        ...,\n",
      "        [0.9661, 0.9855],\n",
      "        [0.9715, 0.9836],\n",
      "        [1.0111, 1.0318]])\n",
      "tensor([[1.0046, 1.0166],\n",
      "        [0.9970, 1.0081],\n",
      "        [0.9305, 0.9401],\n",
      "        ...,\n",
      "        [0.9595, 0.9705],\n",
      "        [0.9727, 0.9842],\n",
      "        [1.0047, 1.0168]])\n",
      "tensor([[1.0153, 1.0237],\n",
      "        [1.0075, 1.0155],\n",
      "        [0.9402, 0.9502],\n",
      "        ...,\n",
      "        [0.9783, 0.9860],\n",
      "        [0.9799, 0.9873],\n",
      "        [1.0466, 1.0456]])\n",
      "tensor([[0.9889, 0.9938],\n",
      "        [1.0159, 1.0266],\n",
      "        [0.9378, 0.9461],\n",
      "        ...,\n",
      "        [0.9720, 0.9818],\n",
      "        [0.9844, 0.9918],\n",
      "        [1.0295, 1.0470]])\n",
      "tensor([[0.9824, 0.9906],\n",
      "        [1.0124, 1.0312],\n",
      "        [0.9428, 0.9545],\n",
      "        ...,\n",
      "        [0.9596, 0.9716],\n",
      "        [0.9805, 0.9959],\n",
      "        [1.0229, 1.0359]])\n",
      "tensor([[0.9913, 1.0068],\n",
      "        [0.9951, 1.0175],\n",
      "        [0.9315, 0.9441],\n",
      "        ...,\n",
      "        [0.9713, 0.9860],\n",
      "        [0.9675, 0.9850],\n",
      "        [1.0376, 1.0668]])\n",
      "tensor([[0.9797, 0.9888],\n",
      "        [0.9906, 1.0066],\n",
      "        [0.9248, 0.9343],\n",
      "        ...,\n",
      "        [0.9678, 0.9842],\n",
      "        [0.9657, 0.9834],\n",
      "        [1.0236, 1.0462]])\n",
      "tensor([[0.9731, 0.9766],\n",
      "        [0.9886, 0.9968],\n",
      "        [0.9190, 0.9306],\n",
      "        ...,\n",
      "        [0.9682, 0.9821],\n",
      "        [0.9680, 0.9798],\n",
      "        [1.0392, 1.0441]])\n",
      "tensor([[0.9813, 0.9931],\n",
      "        [1.0102, 1.0226],\n",
      "        [0.9451, 0.9548],\n",
      "        ...,\n",
      "        [0.9800, 0.9868],\n",
      "        [0.9747, 0.9809],\n",
      "        [1.0409, 1.0508]])\n",
      "tensor([[0.9788, 0.9895],\n",
      "        [1.0227, 1.0416],\n",
      "        [0.9401, 0.9532],\n",
      "        ...,\n",
      "        [0.9830, 0.9958],\n",
      "        [0.9864, 0.9973],\n",
      "        [1.0621, 1.0793]])\n",
      "tensor([[0.9699, 0.9886],\n",
      "        [1.0267, 1.0394],\n",
      "        [0.9394, 0.9539],\n",
      "        ...,\n",
      "        [0.9699, 0.9815],\n",
      "        [0.9893, 1.0050],\n",
      "        [1.0471, 1.0654]])\n",
      "tensor([[0.9747, 0.9898],\n",
      "        [0.9911, 1.0069],\n",
      "        [0.8987, 0.9144],\n",
      "        ...,\n",
      "        [0.9589, 0.9704],\n",
      "        [0.9801, 0.9925],\n",
      "        [1.0094, 1.0213]])\n",
      "tensor([[0.9763, 0.9934],\n",
      "        [1.0250, 1.0398],\n",
      "        [0.9267, 0.9392],\n",
      "        ...,\n",
      "        [0.9858, 1.0020],\n",
      "        [0.9853, 1.0021],\n",
      "        [1.0332, 1.0558]])\n",
      "tensor([[0.9553, 0.9680],\n",
      "        [0.9999, 1.0114],\n",
      "        [0.9119, 0.9207],\n",
      "        ...,\n",
      "        [0.9532, 0.9581],\n",
      "        [0.9710, 0.9834],\n",
      "        [1.0009, 1.0130]])\n",
      "tensor([[1.0027, 1.0098],\n",
      "        [1.0295, 1.0363],\n",
      "        [0.9221, 0.9333],\n",
      "        ...,\n",
      "        [0.9678, 0.9794],\n",
      "        [0.9805, 0.9912],\n",
      "        [1.0494, 1.0578]])\n",
      "tensor([[0.9942, 1.0120],\n",
      "        [1.0212, 1.0317],\n",
      "        [0.9236, 0.9343],\n",
      "        ...,\n",
      "        [0.9514, 0.9694],\n",
      "        [0.9724, 0.9860],\n",
      "        [1.0211, 1.0442]])\n",
      "tensor([[0.9898, 1.0057],\n",
      "        [1.0282, 1.0415],\n",
      "        [0.9430, 0.9539],\n",
      "        ...,\n",
      "        [0.9667, 0.9813],\n",
      "        [0.9961, 1.0082],\n",
      "        [1.0175, 1.0399]])\n",
      "tensor([[0.9831, 1.0031],\n",
      "        [1.0142, 1.0279],\n",
      "        [0.9363, 0.9489],\n",
      "        ...,\n",
      "        [0.9722, 0.9871],\n",
      "        [1.0136, 1.0299],\n",
      "        [1.0511, 1.0698]])\n",
      "tensor([[0.9941, 0.9949],\n",
      "        [1.0173, 1.0270],\n",
      "        [0.9234, 0.9381],\n",
      "        ...,\n",
      "        [0.9809, 0.9921],\n",
      "        [1.0006, 1.0072],\n",
      "        [1.0480, 1.0554]])\n",
      "tensor([[0.9840, 1.0007],\n",
      "        [1.0057, 1.0208],\n",
      "        [0.9425, 0.9532],\n",
      "        ...,\n",
      "        [0.9775, 0.9942],\n",
      "        [1.0003, 1.0075],\n",
      "        [1.0528, 1.0778]])\n",
      "tensor([[0.9861, 0.9983],\n",
      "        [1.0332, 1.0433],\n",
      "        [0.9309, 0.9413],\n",
      "        ...,\n",
      "        [0.9679, 0.9774],\n",
      "        [1.0058, 1.0131],\n",
      "        [1.0572, 1.0685]])\n",
      "tensor([[0.9791, 0.9901],\n",
      "        [1.0252, 1.0352],\n",
      "        [0.9341, 0.9471],\n",
      "        ...,\n",
      "        [0.9604, 0.9777],\n",
      "        [1.0037, 1.0139],\n",
      "        [1.0511, 1.0635]])\n",
      "tensor([[1.0156, 1.0265],\n",
      "        [1.0208, 1.0299],\n",
      "        [0.9396, 0.9504],\n",
      "        ...,\n",
      "        [0.9827, 0.9943],\n",
      "        [0.9746, 0.9857],\n",
      "        [1.0372, 1.0509]])\n",
      "tensor([[0.9851, 0.9969],\n",
      "        [1.0163, 1.0236],\n",
      "        [0.9283, 0.9396],\n",
      "        ...,\n",
      "        [0.9732, 0.9802],\n",
      "        [0.9714, 0.9824],\n",
      "        [1.0278, 1.0407]])\n",
      "tensor([[0.9818, 0.9864],\n",
      "        [1.0214, 1.0354],\n",
      "        [0.9380, 0.9545],\n",
      "        ...,\n",
      "        [0.9725, 0.9871],\n",
      "        [0.9639, 0.9788],\n",
      "        [1.0011, 1.0113]])\n",
      "tensor([[0.9851, 0.9921],\n",
      "        [1.0248, 1.0345],\n",
      "        [0.9318, 0.9396],\n",
      "        ...,\n",
      "        [0.9886, 0.9991],\n",
      "        [0.9726, 0.9903],\n",
      "        [1.0012, 1.0110]])\n",
      "tensor([[0.9902, 1.0065],\n",
      "        [1.0267, 1.0474],\n",
      "        [0.9428, 0.9584],\n",
      "        ...,\n",
      "        [0.9873, 1.0074],\n",
      "        [0.9876, 1.0052],\n",
      "        [1.0494, 1.0726]])\n",
      "tensor([[1.0081, 1.0108],\n",
      "        [1.0060, 1.0204],\n",
      "        [0.9223, 0.9330],\n",
      "        ...,\n",
      "        [0.9595, 0.9676],\n",
      "        [0.9763, 0.9856],\n",
      "        [1.0443, 1.0549]])\n",
      "tensor([[0.9824, 0.9937],\n",
      "        [1.0304, 1.0396],\n",
      "        [0.9428, 0.9472],\n",
      "        ...,\n",
      "        [0.9587, 0.9673],\n",
      "        [0.9884, 0.9982],\n",
      "        [1.0023, 1.0095]])\n",
      "tensor([[0.9981, 1.0145],\n",
      "        [1.0243, 1.0365],\n",
      "        [0.9213, 0.9322],\n",
      "        ...,\n",
      "        [0.9548, 0.9682],\n",
      "        [0.9864, 0.9968],\n",
      "        [1.0129, 1.0294]])\n",
      "tensor([[1.0059, 1.0162],\n",
      "        [1.0385, 1.0458],\n",
      "        [0.9491, 0.9593],\n",
      "        ...,\n",
      "        [0.9668, 0.9781],\n",
      "        [0.9846, 0.9939],\n",
      "        [1.0153, 1.0273]])\n",
      "tensor([[0.9872, 0.9991],\n",
      "        [1.0350, 1.0435],\n",
      "        [0.9302, 0.9409],\n",
      "        ...,\n",
      "        [0.9618, 0.9715],\n",
      "        [0.9895, 0.9945],\n",
      "        [1.0212, 1.0327]])\n",
      "tensor([[0.9749, 0.9905],\n",
      "        [1.0362, 1.0465],\n",
      "        [0.9336, 0.9457],\n",
      "        ...,\n",
      "        [0.9571, 0.9630],\n",
      "        [0.9819, 0.9888],\n",
      "        [1.0134, 1.0267]])\n",
      "tensor([[0.9748, 0.9810],\n",
      "        [1.0294, 1.0422],\n",
      "        [0.9470, 0.9538],\n",
      "        ...,\n",
      "        [0.9502, 0.9633],\n",
      "        [0.9869, 0.9953],\n",
      "        [1.0512, 1.0607]])\n",
      "tensor([[0.9887, 1.0043],\n",
      "        [1.0505, 1.0614],\n",
      "        [0.9507, 0.9606],\n",
      "        ...,\n",
      "        [0.9646, 0.9713],\n",
      "        [0.9856, 0.9953],\n",
      "        [1.0272, 1.0448]])\n",
      "tensor([[0.9896, 0.9960],\n",
      "        [1.0252, 1.0315],\n",
      "        [0.9588, 0.9680],\n",
      "        ...,\n",
      "        [0.9627, 0.9693],\n",
      "        [0.9906, 0.9967],\n",
      "        [1.0216, 1.0320]])\n",
      "tensor([[0.9982, 1.0062],\n",
      "        [1.0342, 1.0446],\n",
      "        [0.9511, 0.9595],\n",
      "        ...,\n",
      "        [0.9528, 0.9580],\n",
      "        [0.9967, 1.0064],\n",
      "        [1.0238, 1.0367]])\n",
      "tensor([[0.9839, 0.9971],\n",
      "        [1.0204, 1.0305],\n",
      "        [0.9373, 0.9484],\n",
      "        ...,\n",
      "        [0.9414, 0.9455],\n",
      "        [0.9848, 0.9979],\n",
      "        [1.0131, 1.0256]])\n",
      "tensor([[0.9954, 1.0024],\n",
      "        [1.0394, 1.0493],\n",
      "        [0.9399, 0.9491],\n",
      "        ...,\n",
      "        [0.9529, 0.9599],\n",
      "        [0.9980, 1.0051],\n",
      "        [1.0228, 1.0306]])\n",
      "tensor([[0.9952, 1.0038],\n",
      "        [1.0171, 1.0248],\n",
      "        [0.9521, 0.9616],\n",
      "        ...,\n",
      "        [0.9583, 0.9656],\n",
      "        [0.9932, 1.0088],\n",
      "        [1.0180, 1.0278]])\n",
      "tensor([[0.9739, 0.9820],\n",
      "        [1.0177, 1.0338],\n",
      "        [0.9532, 0.9639],\n",
      "        ...,\n",
      "        [0.9640, 0.9722],\n",
      "        [0.9792, 0.9917],\n",
      "        [1.0265, 1.0373]])\n",
      "tensor([[0.9860, 0.9972],\n",
      "        [1.0382, 1.0453],\n",
      "        [0.9442, 0.9508],\n",
      "        ...,\n",
      "        [0.9596, 0.9655],\n",
      "        [0.9781, 0.9875],\n",
      "        [1.0095, 1.0205]])\n",
      "tensor([[0.9877, 0.9965],\n",
      "        [1.0119, 1.0187],\n",
      "        [0.9398, 0.9447],\n",
      "        ...,\n",
      "        [0.9586, 0.9645],\n",
      "        [0.9812, 0.9897],\n",
      "        [1.0114, 1.0218]])\n",
      "tensor([[1.0145, 1.0228],\n",
      "        [1.0308, 1.0423],\n",
      "        [0.9395, 0.9498],\n",
      "        ...,\n",
      "        [0.9570, 0.9693],\n",
      "        [0.9941, 1.0065],\n",
      "        [1.0222, 1.0329]])\n",
      "tensor([[0.9784, 0.9923],\n",
      "        [1.0406, 1.0482],\n",
      "        [0.9311, 0.9408],\n",
      "        ...,\n",
      "        [0.9535, 0.9658],\n",
      "        [0.9930, 1.0027],\n",
      "        [1.0172, 1.0362]])\n"
     ]
    }
   ],
   "source": [
    "for config in configs[:1]:\n",
    "    run_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ec05a26f12930ec341a8988c0de5d31e9cfb37c98ea12af5353828508f2c236"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
