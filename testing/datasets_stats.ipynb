{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats.contingency import relative_risk\n",
    "from math import isnan\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_reward_fn(vec):\n",
    "    # Determined by polypharmacy definition\n",
    "    if vec.sum() < 5:\n",
    "        return 0\n",
    "\n",
    "    vec_indices = torch.where(vec == 1)[0]\n",
    "\n",
    "    # Exposed\n",
    "    rows_exposed = torch.where((X[:, vec_indices] == 1).all(axis=1))[\n",
    "        0\n",
    "    ]\n",
    "    rows_control = torch.where((X[:, vec_indices] == 0).any(axis=1))[\n",
    "        0\n",
    "    ]\n",
    "\n",
    "    rows_exposed_case = torch.where(y[rows_exposed] == 1)[0]\n",
    "    rows_control_case = torch.where(y[rows_control] == 1)[0]\n",
    "\n",
    "    n_exposed = len(rows_exposed)\n",
    "    n_exposed_case = len(rows_exposed_case)\n",
    "    n_control = len(rows_control)\n",
    "    n_control_case = len(rows_control_case)\n",
    "    rr = relative_risk(n_exposed_case, n_exposed, n_control_case, n_control).relative_risk\n",
    "    \n",
    "    if isnan(rr):\n",
    "        # Interpreted as 0 by experts\n",
    "        return 0\n",
    "\n",
    "    elif rr == float('inf'):\n",
    "        return 10   # Return something really big, but not inf so it doesn't break the regression\n",
    "\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150: 0\n",
      "150: 1\n",
      "150: 2\n",
      "150: 3\n",
      "150: 4\n",
      "150: 5\n",
      "150: 6\n",
      "150: 7\n",
      "150: 8\n",
      "150: 9\n",
      "150: 10\n",
      "150: 11\n",
      "150: 12\n",
      "150: 13\n",
      "150: 14\n",
      "150: 15\n",
      "150: 16\n",
      "150: 17\n",
      "150: 18\n",
      "150: 19\n",
      "150: 20\n",
      "150: 21\n",
      "150: 22\n",
      "150: 23\n",
      "150: 24\n",
      "150: 25\n",
      "150: 26\n",
      "150: 27\n",
      "150: 28\n",
      "150: 29\n",
      "150: 30\n",
      "150: 31\n",
      "150: 32\n",
      "150: 33\n",
      "150: 34\n",
      "150: 35\n",
      "150: 36\n",
      "150: 37\n",
      "150: 38\n",
      "150: 39\n",
      "150: 40\n",
      "150: 41\n",
      "150: 42\n",
      "150: 43\n",
      "150: 44\n",
      "150: 45\n",
      "150: 46\n",
      "150: 47\n",
      "150: 48\n",
      "150: 49\n",
      "150: 50\n",
      "150: 51\n",
      "150: 52\n",
      "150: 53\n",
      "150: 54\n",
      "150: 55\n",
      "150: 56\n",
      "150: 57\n",
      "150: 58\n",
      "150: 59\n",
      "150: 60\n",
      "150: 61\n",
      "150: 62\n",
      "150: 63\n",
      "150: 64\n",
      "150: 65\n",
      "150: 66\n",
      "150: 67\n",
      "150: 68\n",
      "150: 69\n",
      "150: 70\n",
      "150: 71\n",
      "150: 72\n",
      "150: 73\n",
      "150: 74\n",
      "150: 75\n",
      "150: 76\n",
      "150: 77\n",
      "150: 78\n",
      "150: 79\n",
      "150: 80\n",
      "150: 81\n",
      "150: 82\n",
      "150: 83\n",
      "150: 84\n",
      "150: 85\n",
      "150: 86\n",
      "150: 87\n",
      "150: 88\n",
      "150: 89\n",
      "150: 90\n",
      "150: 91\n",
      "150: 92\n",
      "150: 93\n",
      "150: 94\n",
      "150: 95\n",
      "150: 96\n",
      "150: 97\n",
      "150: 98\n",
      "150: 99\n",
      "550: 0\n",
      "550: 1\n",
      "550: 2\n",
      "550: 3\n",
      "550: 4\n",
      "550: 5\n",
      "550: 6\n",
      "550: 7\n",
      "550: 8\n",
      "550: 9\n",
      "550: 10\n",
      "550: 11\n",
      "550: 12\n",
      "550: 13\n",
      "550: 14\n",
      "550: 15\n",
      "550: 16\n",
      "550: 17\n",
      "550: 18\n",
      "550: 19\n",
      "550: 20\n",
      "550: 21\n",
      "550: 22\n",
      "550: 23\n",
      "550: 24\n",
      "550: 25\n",
      "550: 26\n",
      "550: 27\n",
      "550: 28\n",
      "550: 29\n",
      "550: 30\n",
      "550: 31\n",
      "550: 32\n",
      "550: 33\n",
      "550: 34\n",
      "550: 35\n",
      "550: 36\n",
      "550: 37\n",
      "550: 38\n",
      "550: 39\n",
      "550: 40\n",
      "550: 41\n",
      "550: 42\n",
      "550: 43\n",
      "550: 44\n",
      "550: 45\n",
      "550: 46\n",
      "550: 47\n",
      "550: 48\n",
      "550: 49\n",
      "550: 50\n",
      "550: 51\n",
      "550: 52\n",
      "550: 53\n",
      "550: 54\n",
      "550: 55\n",
      "550: 56\n",
      "550: 57\n",
      "550: 58\n",
      "550: 59\n",
      "550: 60\n",
      "550: 61\n",
      "550: 62\n",
      "550: 63\n",
      "550: 64\n",
      "550: 65\n",
      "550: 66\n",
      "550: 67\n",
      "550: 68\n",
      "550: 69\n",
      "550: 70\n",
      "550: 71\n",
      "550: 72\n",
      "550: 73\n",
      "550: 74\n",
      "550: 75\n",
      "550: 76\n",
      "550: 77\n",
      "550: 78\n",
      "550: 79\n",
      "550: 80\n",
      "550: 81\n",
      "550: 82\n",
      "550: 83\n",
      "550: 84\n",
      "550: 85\n",
      "550: 86\n",
      "550: 87\n",
      "550: 88\n",
      "550: 89\n",
      "550: 90\n",
      "550: 91\n",
      "550: 92\n",
      "550: 93\n",
      "550: 94\n",
      "550: 95\n",
      "550: 96\n",
      "550: 97\n",
      "550: 98\n",
      "550: 99\n",
      "1600: 0\n",
      "1600: 1\n",
      "1600: 2\n",
      "1600: 3\n",
      "1600: 4\n",
      "1600: 5\n",
      "1600: 6\n",
      "1600: 7\n",
      "1600: 8\n",
      "1600: 9\n",
      "1600: 10\n",
      "1600: 11\n",
      "1600: 12\n",
      "1600: 13\n",
      "1600: 14\n",
      "1600: 15\n",
      "1600: 16\n",
      "1600: 17\n",
      "1600: 18\n",
      "1600: 19\n",
      "1600: 20\n",
      "1600: 21\n",
      "1600: 22\n",
      "1600: 23\n",
      "1600: 24\n",
      "1600: 25\n",
      "1600: 26\n",
      "1600: 27\n",
      "1600: 28\n",
      "1600: 29\n",
      "1600: 30\n",
      "1600: 31\n",
      "1600: 32\n",
      "1600: 33\n",
      "1600: 34\n",
      "1600: 35\n",
      "1600: 36\n",
      "1600: 37\n",
      "1600: 38\n",
      "1600: 39\n",
      "1600: 40\n",
      "1600: 41\n",
      "1600: 42\n",
      "1600: 43\n",
      "1600: 44\n",
      "1600: 45\n",
      "1600: 46\n",
      "1600: 47\n",
      "1600: 48\n",
      "1600: 49\n",
      "1600: 50\n",
      "1600: 51\n",
      "1600: 52\n",
      "1600: 53\n",
      "1600: 54\n",
      "1600: 55\n",
      "1600: 56\n",
      "1600: 57\n",
      "1600: 58\n",
      "1600: 59\n",
      "1600: 60\n",
      "1600: 61\n",
      "1600: 62\n",
      "1600: 63\n",
      "1600: 64\n",
      "1600: 65\n",
      "1600: 66\n",
      "1600: 67\n",
      "1600: 68\n",
      "1600: 69\n",
      "1600: 70\n",
      "1600: 71\n",
      "1600: 72\n",
      "1600: 73\n",
      "1600: 74\n",
      "1600: 75\n",
      "1600: 76\n",
      "1600: 77\n",
      "1600: 78\n",
      "1600: 79\n",
      "1600: 80\n",
      "1600: 81\n",
      "1600: 82\n",
      "1600: 83\n",
      "1600: 84\n",
      "1600: 85\n",
      "1600: 86\n",
      "1600: 87\n",
      "1600: 88\n",
      "1600: 89\n",
      "1600: 90\n",
      "1600: 91\n",
      "1600: 92\n",
      "1600: 93\n",
      "1600: 94\n",
      "1600: 95\n",
      "1600: 96\n",
      "1600: 97\n",
      "1600: 98\n",
      "1600: 99\n"
     ]
    }
   ],
   "source": [
    "min_risks = []\n",
    "max_risks = []\n",
    "avg_n_rx = []\n",
    "ds = [150, 550, 1600]\n",
    "for n_dim in ds:\n",
    "    for run_number in range(100):\n",
    "        print(f\"{n_dim}: {run_number}\")\n",
    "        df = pd.read_csv(f\"datasets/polypharmacie/10000r_{n_dim}c_1o_run{run_number}.csv\")\n",
    "\n",
    "        with open(f\"datasets/polypharmacie/10000r_{n_dim}c_1o_run{run_number}_config.json\", \"r\") as file:\n",
    "            config = json.load(file)\n",
    "\n",
    "        with open(f\"datasets/polypharmacie/10000r_{n_dim}c_1o_run{run_number}.json\", \"r\") as file:\n",
    "            pattern_config = json.load(file)\n",
    "\n",
    "        pattern_codes = [\n",
    "            np.array(pattern_config[f\"pattern_{i}\"][\"code_indices\"]) - 1 for i in range(10)\n",
    "        ]\n",
    "\n",
    "        n_medical_codes = config[\"n_medical_codes\"]\n",
    "        n_outcomes = config[\"n_outcomes\"]\n",
    "        column_names = (\n",
    "            [\"patient_id\"]\n",
    "            + [f\"medical_code_{i}\" for i in range(n_medical_codes)]\n",
    "            + [f\"outcome_code_{i}\" for i in range(n_outcomes)]\n",
    "        )\n",
    "\n",
    "        df.columns = column_names\n",
    "\n",
    "        X_df = df.iloc[:, 1 : n_medical_codes + 1]\n",
    "        X = X_df.values\n",
    "\n",
    "        y_df = df.iloc[:, n_medical_codes + 1 : n_medical_codes + 1 + n_outcomes]\n",
    "        y = y_df.values.ravel()\n",
    "\n",
    "        X_df.describe()\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).cpu()\n",
    "        set_existing_vecs = torch.unique(X, dim=0).float()\n",
    "\n",
    "\n",
    "        risks = []\n",
    "        epsilon = 0.4\n",
    "        inv_eps = 1 - epsilon\n",
    "        for vec in set_existing_vecs:\n",
    "            risks.append(risk_reward_fn(vec))\n",
    "\n",
    "        risks = np.array(risks)\n",
    "\n",
    "        max_risk = max(risks)\n",
    "        min_risk = min(risks)\n",
    "        max_risks.append(max_risk)\n",
    "        min_risks.append(min_risk)\n",
    "\n",
    "        n_rx_in_dataset = 0\n",
    "        for row in X:\n",
    "            n_rx_in_dataset += row.sum()\n",
    "\n",
    "        avg_n_rx.append(n_rx_in_dataset / len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max avg_n_rx\n",
      "6.189119\n",
      "12.693469\n",
      "min and max min_risks\n",
      "0.0\n",
      "0.0\n",
      "min and max max_risks\n",
      "1.7732434350603266\n",
      "3.7899127796738723\n"
     ]
    }
   ],
   "source": [
    "print(\"min and max avg_n_rx\")\n",
    "print(np.min(avg_n_rx))\n",
    "print(np.max(avg_n_rx))\n",
    "\n",
    "print(\"min and max min_risks\")\n",
    "print(np.min(min_risks))\n",
    "print(np.max(min_risks))\n",
    "\n",
    "print(\"min and max max_risks\")\n",
    "print(np.min(max_risks))\n",
    "print(np.max(max_risks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max avg_n_rx\n",
      "8.419142\n",
      "12.693469\n",
      "min and max min_risks\n",
      "0.0\n",
      "0.0\n",
      "min and max max_risks\n",
      "1.7800142500890632\n",
      "3.7515015015015014\n"
     ]
    }
   ],
   "source": [
    "idx_start = 0\n",
    "idx_end = 100\n",
    "print(\"min and max avg_n_rx\")\n",
    "print(np.min(avg_n_rx[idx_start: idx_end]))\n",
    "print(np.max(avg_n_rx[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max min_risks\")\n",
    "print(np.min(min_risks[idx_start: idx_end]))\n",
    "print(np.max(min_risks[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max max_risks\")\n",
    "print(np.min(max_risks[idx_start: idx_end]))\n",
    "print(np.max(max_risks[idx_start: idx_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max avg_n_rx\n",
      "6.189119\n",
      "10.921092\n",
      "min and max min_risks\n",
      "0.0\n",
      "0.0\n",
      "min and max max_risks\n",
      "1.8174704276615103\n",
      "3.64272694130514\n"
     ]
    }
   ],
   "source": [
    "idx_start = 100\n",
    "idx_end = 200\n",
    "print(\"min and max avg_n_rx\")\n",
    "print(np.min(avg_n_rx[idx_start: idx_end]))\n",
    "print(np.max(avg_n_rx[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max min_risks\")\n",
    "print(np.min(min_risks[idx_start: idx_end]))\n",
    "print(np.max(min_risks[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max max_risks\")\n",
    "print(np.min(max_risks[idx_start: idx_end]))\n",
    "print(np.max(max_risks[idx_start: idx_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min and max avg_n_rx\n",
      "7.0354037\n",
      "11.89909\n",
      "min and max min_risks\n",
      "0.0\n",
      "0.0\n",
      "min and max max_risks\n",
      "1.7732434350603266\n",
      "3.7899127796738723\n"
     ]
    }
   ],
   "source": [
    "idx_start = 200\n",
    "idx_end = 300\n",
    "print(\"min and max avg_n_rx\")\n",
    "print(np.min(avg_n_rx[idx_start: idx_end]))\n",
    "print(np.max(avg_n_rx[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max min_risks\")\n",
    "print(np.min(min_risks[idx_start: idx_end]))\n",
    "print(np.max(min_risks[idx_start: idx_end]))\n",
    "\n",
    "print(\"min and max max_risks\")\n",
    "print(np.min(max_risks[idx_start: idx_end]))\n",
    "print(np.max(max_risks[idx_start: idx_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7074b7c4a348c76f53c4973f49148425917fc9abc236bb5968d2ddc5e184768"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
